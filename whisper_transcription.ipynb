{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Transcription\n",
    "\n",
    "Simple audio transcription following OpenAI \"getting started\" guide for the whisper API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: python-dotenv in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: pydub in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.25.1)\n",
      "Requirement already satisfied: docx in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.2.4)\n",
      "Collecting onnxruntime (from -r requirements.txt (line 6))\n",
      "  Downloading onnxruntime-1.16.3-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyannote.audio in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: unstructured[docx] in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.11.8)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (2.5.3)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.conda/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: lxml in ./.conda/lib/python3.11/site-packages (from docx->-r requirements.txt (line 4)) (5.1.0)\n",
      "Requirement already satisfied: Pillow>=2.0 in ./.conda/lib/python3.11/site-packages (from docx->-r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: chardet in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: filetype in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (0.4.27)\n",
      "Requirement already satisfied: nltk in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: tabulate in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: emoji in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: rapidfuzz in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (3.6.1)\n",
      "Requirement already satisfied: backoff in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (0.15.1)\n",
      "Requirement already satisfied: wrapt in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: python-docx>=1.1.0 in ./.conda/lib/python3.11/site-packages (from unstructured[docx]->-r requirements.txt (line 5)) (1.1.0)\n",
      "Collecting coloredlogs (from onnxruntime->-r requirements.txt (line 6))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime->-r requirements.txt (line 6))\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in ./.conda/lib/python3.11/site-packages (from onnxruntime->-r requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: protobuf in ./.conda/lib/python3.11/site-packages (from onnxruntime->-r requirements.txt (line 6)) (4.25.1)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.11/site-packages (from onnxruntime->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.20.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (13.7.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: speechbrain>=0.5.14 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.5.16)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: torchaudio>=2.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in ./.conda/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio->-r requirements.txt (line 7)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio->-r requirements.txt (line 7)) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio->-r requirements.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in ./.conda/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: pytorch-lightning in ./.conda/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./.conda/lib/python3.11/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio->-r requirements.txt (line 7)) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in ./.conda/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio->-r requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in ./.conda/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio->-r requirements.txt (line 7)) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.19 in ./.conda/lib/python3.11/site-packages (from pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (2.1.4)\n",
      "Requirement already satisfied: typer>=0.2.1 in ./.conda/lib/python3.11/site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in ./.conda/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in ./.conda/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (0.6.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in ./.conda/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (3.8.2)\n",
      "Requirement already satisfied: optuna>=3.1 in ./.conda/lib/python3.11/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.14.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio->-r requirements.txt (line 7)) (2.17.2)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.conda/lib/python3.11/site-packages (from soundfile>=0.12.1->pyannote.audio->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in ./.conda/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio->-r requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: sentencepiece in ./.conda/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio->-r requirements.txt (line 7)) (0.1.99)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/lib/python3.11/site-packages (from sympy->onnxruntime->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.11/site-packages (from torch>=2.0.0->pyannote.audio->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.11/site-packages (from torch>=2.0.0->pyannote.audio->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in ./.conda/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in ./.conda/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in ./.conda/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (1.2.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.conda/lib/python3.11/site-packages (from beautifulsoup4->unstructured[docx]->-r requirements.txt (line 5)) (2.5)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r requirements.txt (line 6))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json->unstructured[docx]->-r requirements.txt (line 5)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json->unstructured[docx]->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: six in ./.conda/lib/python3.11/site-packages (from langdetect->unstructured[docx]->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: click in ./.conda/lib/python3.11/site-packages (from nltk->unstructured[docx]->-r requirements.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.conda/lib/python3.11/site-packages (from nltk->unstructured[docx]->-r requirements.txt (line 5)) (2023.12.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests->unstructured[docx]->-r requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests->unstructured[docx]->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./.conda/lib/python3.11/site-packages (from unstructured-client->unstructured[docx]->-r requirements.txt (line 5)) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./.conda/lib/python3.11/site-packages (from unstructured-client->unstructured[docx]->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from unstructured-client->unstructured[docx]->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pycparser in ./.conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio->-r requirements.txt (line 7)) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.conda/lib/python3.11/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (3.9.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.0 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.11/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (69.0.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.conda/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: colorlog in ./.conda/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (6.8.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.conda/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (2.0.25)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.conda/lib/python3.11/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: primePy>=1.3 in ./.conda/lib/python3.11/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (1.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in ./.conda/lib/python3.11/site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in ./.conda/lib/python3.11/site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in ./.conda/lib/python3.11/site-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->-r requirements.txt (line 7)) (0.18.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->pyannote.audio->-r requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: Mako in ./.conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./.conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.conda/lib/python3.11/site-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./.conda/lib/python3.11/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->-r requirements.txt (line 7)) (0.2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->-r requirements.txt (line 7)) (3.0.3)\n",
      "Downloading onnxruntime-1.16.3-cp311-cp311-macosx_10_15_x86_64.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-23.5.26 humanfriendly-10.0 onnxruntime-1.16.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env variables\n",
    "\n",
    "import os\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic OpenAI Whisper API Transcription\n",
    "\n",
    "Essentially a copy of the OpenAI \"getting started\" guide for the whisper API, but with a few tweaks to make it work for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk0.mp3\n",
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk1.mp3\n",
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk2.mp3\n",
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk3.mp3\n",
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk4.mp3\n",
      "exporting audio/hwb_user_interviews/charlott practitioner north/charlott practitioner north_chunk5.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "# Set the audio path we want to work on\n",
    "input_audio_path = \"audio/hwb_user_interviews/charlott practitioner north.mp3\"\n",
    "\n",
    "output_folder = os.path.join(os.path.dirname(input_audio_path), os.path.basename(input_audio_path).split('.')[0])\n",
    "subject_name = os.path.basename(input_audio_path).split('.')[0]\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "myaudio = AudioSegment.from_file(input_audio_path, format=input_audio_path.split(\".\")[-1])\n",
    "chunk_length_ms = 600000  # 10 minutes in milliseconds\n",
    "chunks = make_chunks(myaudio, chunk_length_ms)  # Make chunks of 10 minutes\n",
    "chunk_paths = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = f\"{output_folder}/{subject_name}_chunk{i}.{input_audio_path.split('.')[-1]}\"\n",
    "    chunk_paths.append(chunk_name)\n",
    "    print(\"exporting\", chunk_name)\n",
    "    chunk.export(chunk_name, format=input_audio_path.split(\".\")[-1])\n",
    "\n",
    "#  chunks now contains the 10 minute a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # api_key=\"My API Key\",\n",
    ")\n",
    "\n",
    "def transcribe_audio_obj(model, prompt, response_format, audio_file):\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            response_format=response_format,\n",
    "            file=audio_file,\n",
    "            language=\"en\",\n",
    "        )\n",
    "    \n",
    "    return transcript\n",
    "\n",
    "def transcribe_audio(audio_file_path=\"\", model=\"whisper-1\", prompt=\"Transcribe the following audio?\", response_format=\"srt\"):\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = transcribe_audio_obj(model, prompt, response_format, audio_file)\n",
    "        print(f\"transcribed audio file: {audio_file_path}\")\n",
    "    return transcript\n",
    "\n",
    "\n",
    "# def transcribe_chunk(audio_segment=None, model=\"whisper-1\", prompt=\"Transcribe the following audio?\", response_format=\"srt\"):\n",
    "#     with audio_segment.export() as audio_file:\n",
    "#         transcript = transcribe_audio_obj(\n",
    "#             model, prompt, response_format, audio_file)\n",
    "#         print(f\"transcribed audio file: {audio_file_path}\")\n",
    "#     return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each item in chunk_paths, transcribe it and write the result to a text file, names the same as the audio file with a txt extension\n",
    "def transcribe_files(file_list=[], prompt=\"Transribe this audio as accurately as possible.\"):\n",
    "    for i, file_path in enumerate(file_list):\n",
    "        transcript = transcribe_audio(file_path, prompt=\"Interview with Charlott, a teacher from North Wales, about her use of and opinions about the Hwb learning platform and the suite of online teaching and learning tools it proides.\")\n",
    "        with open(f\"{file_path}.txt\", \"w\") as f:\n",
    "            f.write(transcript)\n",
    "        print(f\"wrote transcript to {file_path}.txt\")\n",
    "\n",
    "# transcribe_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk4.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk4.mp3.txt\n",
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk5.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk5.mp3.txt\n",
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk2.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk2.mp3.txt\n",
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk3.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk3.mp3.txt\n",
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk1.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk1.mp3.txt\n",
      "transcribed audio file: audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3\n",
      "wrote transcript to audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3.txt\n"
     ]
    }
   ],
   "source": [
    "# find all the mp3 files in the given path. return a list of paths to the mp3 files\n",
    "\n",
    "def find_mp3s(path):\n",
    "    mp3s = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                mp3s.append(os.path.join(root, file))\n",
    "    return mp3s\n",
    "\n",
    "\n",
    "gareth_mp3s = find_mp3s(\"audio/hwb_user_interviews/gareth gwyr\")\n",
    "\n",
    "transcribe_files(gareth_mp3s, prompt=\"An interview with a teacher at Gwyr comprehensive school in Swansea, about the use of the Hwb learning platform and its suite of online tools.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "transcript = transcribe_audio(\n",
    "    audio_file_path=\"audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3\",\n",
    "    prompt=\"An interview with a teacher at Gwyr comprehensive school about the use of the Hwb learning platform and its suite of online tools.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n00:00:00,000 --> 00:00:21,000\\nI was head of IT at Gwyr, I'm head of computer science at Gwyr, but I've been here for 25 years, I know I'm only 21, and I've used Hwb since day one really, bit slow getting into it.\\n\\n2\\n00:00:21,000 --> 00:00:44,000\\nI'm not head of, well I am head of department now, but I've changed now to head of digital strategy across the school, so I look after, I did anyway, but they've kind of given it a new term now, because we were looking for another IT teacher, we couldn't get anyone, so we advertised for a head of department and I went sideways to a new title, but we couldn't get anyone.\\n\\n3\\n00:00:44,000 --> 00:00:58,000\\nBecause I know you, I know what you're referring to, but for Ines who probably doesn't know, my understanding from when we've known each other a long time is you were kind of looking after the IT systems, doing a lot of non-teaching sort of functions, are you still teaching?\\n\\n4\\n00:00:58,000 --> 00:01:27,000\\nYeah, I still teach, but I've got a smaller timetable now, so I can get on with other stuff. I kind of think, I know it sounds arrogant, but I am unique in Swansea, there's no other, I already know this from talking to other heads of department, but there's no one else who does the same type of role, I mean if you think, I do the role of three people, but they do look after me regarding my teaching timetable.\\n\\n5\\n00:01:27,000 --> 00:01:40,000\\nSo if you were going to break that down, those three roles and what you actually do in your day, you're kind of like daily, what's a typical day look like for Mr Edmondson, how would you describe that with all those hats you wear?\\n\\n6\\n00:01:40,000 --> 00:02:07,000\\nI get into work about half past eight, well earlier than that, I don't do any registration duties, I'm not a form tutor anymore, my job, I rally up the technical staff, make sure they know what they're doing for the day, I walk into my office, which is the main server room, check there's no red lights, or no all these lights on any of our hardware, and then I deal, until nine o'clock, I deal with my emails.\\n\\n7\\n00:02:07,000 --> 00:02:23,000\\nOne of the biggest things I've had to learn this year is time management, I've got to manage my time better, I look at my timetable for the day, and I sort my lessons out, like this morning I was free first lesson, and then I teach an all day, luckily this afternoon I've got year 12, so they're getting more stuff in there.\\n\\n8\\n00:02:23,000 --> 00:02:47,000\\nMy timetable has gone, it's a fortnightly timetable, originally I went up to 20 or 60 teaching lessons, but I'm back up to 31 now for various reasons and various staff have been moved about. Originally it was just me as the teacher, but now we've got another member of staff as well, so that's really helped me a lot to do the job I can do.\\n\\n9\\n00:02:47,000 --> 00:03:03,000\\nWe've just been through Estyn, and they were impressed with the department, and they want to come back and do a case study on how we've integrated computer science right across the curriculum, and we do it in year 7.\\n\\n10\\n00:03:03,000 --> 00:03:10,000\\nAnd you said you're unique in terms of Swansea, why would you say that's unique, the set up in Goyer is different to other schools?\\n\\n11\\n00:03:10,000 --> 00:03:32,000\\nBecause most of the other schools, most of the other comps have got network managers, which I am the network manager, they've got someone who may be responsible for the digital framework, well I'm responsible for the digital framework, I'm responsible for my department, so it's actually a case of juggling everything and making sure it fits, I have to plan my week.\\n\\n12\\n00:03:33,000 --> 00:03:42,000\\nAre you still doing day-to-day tech support? I know at one point you were looking for the tech support aspect of it as well, so there's a lot on your plate.\\n\\n13\\n00:03:42,000 --> 00:04:01,000\\nWe lost our technician just before Christmas, so at the moment it is falling to me, but usually I'm second line support, whereas 25 years builds up a lot of experience, where a technician who might be a year into the job might not have that experience.\\n\\n14\\n00:04:02,000 --> 00:04:26,000\\nSo if the technician can't solve the issue, then I come in as second line, and then if we can't solve the issue we go outside as well. But usually we do a lot of stuff in-house, for example I've got a laptop cabinet just over there, which is a mess, so the other technician is so busy that I'm doing it.\\n\\n15\\n00:04:27,000 --> 00:04:35,000\\nI'm teaching as well, so do you get any time for anything outside of work? I know you've got a family and you used to run.\\n\\n16\\n00:04:36,000 --> 00:04:59,000\\nI refuse to work outside of school hours. If I have to do something, I will, but every day I set an out of office to kick in at four o'clock to say I'll answer any emails on the next working day, and if I'm doing something I'll do it. But once I get home, once I leave here at four o'clock, I try not to do anything, otherwise my head will blow up.\\n\\n17\\n00:05:00,000 --> 00:05:04,000\\nSo that time management and delineation, uncoupling yourself.\\n\\n18\\n00:05:05,000 --> 00:05:06,000\\nI do that, I do that.\\n\\n19\\n00:05:08,000 --> 00:05:21,000\\nBecause people we wouldn't know, I'd say tell us about your home life, and I kind of know you in that sense anyway, so it feels a bit weird asking you about your kid's car, what your home is, because I can fill in the blanks a bit.\\n\\n20\\n00:05:22,000 --> 00:05:49,000\\nSo, you know, just before we sort of talk about hub and things, because it's really good to get a sense of like your challenges and your goals and stuff, and how the hub might fit in that and enable some of those tasks that you've got to do, but what are your, you know, in terms of your role and the kind of multiple roles that you do, what would you say your sort of goals and aspirations are for your particular role, and there may be some of the challenges around that, but what do you want to achieve in your role, Gareth?\\n\\n21\\n00:05:49,000 --> 00:06:12,000\\nI think, well, at the moment I'm not going to go higher, I want to, you know, get the ed or whatever, you know, that's the plan, and I'm doing courses to do that, but, you know, every teacher, my role is to make sure my department succeeds, even though the department now is less important for my role, that's still, you know, teacher first, technical second.\\n\\n22\\n00:06:12,000 --> 00:06:13,000\\nYeah, sure.\\n\\n23\\n00:06:14,000 --> 00:06:31,000\\nBut I do, I'm proud of what we've built here over 25 years that I've been here, and it works, we very rarely, I'm looking at the servers below now, we very rarely have downtime, very, very rarely does anything break, which is quite boring sometimes, because you want something to break to see what you're supposed to do.\\n\\n24\\n00:06:32,000 --> 00:06:58,000\\nBut it was a situation where I'd look for the next big thing, but, you know, I push hub as part of my DCF work, we use hub in the department, well, I wouldn't say we use hub in the department, we use the Microsoft aspect, you know, we use Teams and all that, that's my focus, I mean, we get off to hub and in, hub is hub, you know, it's good for what it is,\\n\\n25\\n00:06:58,000 --> 00:07:05,000\\nbut I think that probably the reason we do use hub is because Microsoft, it gives Microsoft Office for free.\\n\\n26\\n00:07:05,000 --> 00:07:18,000\\nI mean, we can talk about, we can talk about hub, well, we'll park it for a sec, but that is interesting, because we talk about, you know, what aspects you use and whether it's a gateway just to use the kind of free aspects of what you use on there, so we will definitely come back to that.\\n\\n27\\n00:07:18,000 --> 00:07:27,000\\nAnd what about any sort of kind of challenges that you have within your role generally, you know, to stop you getting where you need to get to?\\n\\n28\\n00:07:28,000 --> 00:07:48,000\\nI think that a lot of the time management was one of the challenges, getting old, but now the headteacher's sorted that out. He's gone back on a couple of things, which is frustrating, like I said, I was 20 lessons a fortnight, now I'm 31 lessons a fortnight, but I'm still blessed with the amount of free time I get.\\n\\n29\\n00:07:49,000 --> 00:08:07,000\\nOther challenges, I know it sounds awful, but the older teachers are a challenge. I'm 48, but trying to get a 58 year old to use hub is a nightmare. That's the biggest, one of the biggest challenges, making sure people turn up for training sessions.\\n\\n30\\n00:08:07,000 --> 00:08:33,000\\nSo, you know, if you don't turn up for my training session, I've got to find time to meet you again then, to find out why you haven't turned up and to make sure you are trained up. Other things are, because people, the attitude of, if it's got a plug, it belongs to Gareth. You know, if it's got a plug, Gareth will fix it, which isn't fair sometimes.\\n\\n31\\n00:08:33,000 --> 00:08:56,000\\nThere's also the issue, we had a member of staff go off with cancer last year, and nobody else knew how to do her job. So I was asked, can you step in? And, you know, being technical, I was able to pick her up within a day and everything was sorted. And for six months I did her job as well.\\n\\n32\\n00:08:57,000 --> 00:09:07,000\\nSo I think that's another barrier, there's not enough people to cover people, if that makes sense. There should always be two people who can do one job.\\n\\n33\\n00:09:08,000 --> 00:09:20,000\\nSo this pressure on your time is quite acute, and when you've got a teacher who has some time, the natural inclination of a school leader is to pop that person in because they've got a few spare lessons to cover, instead of having succession planning.\\n\\n34\\n00:09:21,000 --> 00:09:38,000\\nI'll give you an example. This morning, I arrived at Hapus 8. My first lesson wasn't until 9.50. So I sat, you know, I've got a campervan. So in the school car park, I put the table up in the campervan, I sat in the campervan for an hour and did my work in the campervan.\\n\\n35\\n00:09:39,000 --> 00:09:50,000\\nSo, because no one would have known where I was. Well, I got an office, but people would come in and out as they went. So I messaged my department and said, look, I'm going to sit in the van for an hour.\\n\\n36\\n00:09:50,000 --> 00:09:52,000\\nJust to get some peace, to get things done.\\n\\n37\\n00:09:52,000 --> 00:09:57,000\\nYeah, and I was able to do loads. I was in nearby about a quarter to ten then.\\n\\n38\\n00:09:57,000 --> 00:09:58,000\\nOkay.\\n\\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Diarization\n",
    "\n",
    "Experiment with [`pyannote.audio`](https://github.com/pyannote/pyannote-audio), an open-source toolkit written in Python for **speaker diarization**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(23515) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Collecting einops>=0.6.0 (from pyannote.audio)\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub>=0.13.0 (from pyannote.audio)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
      "  Downloading lightning-2.1.3-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<3.0,>=2.1 (from pyannote.audio)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.database-5.0.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.4.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rich>=12.0.0 (from pyannote.audio)\n",
      "  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio)\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting soundfile>=0.12.1 (from pyannote.audio)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting speechbrain>=0.5.14 (from pyannote.audio)\n",
      "  Downloading speechbrain-0.5.16-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torch>=2.0.0 (from pyannote.audio)\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio>=2.0.0 (from pyannote.audio)\n",
      "  Downloading torchaudio-2.1.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.26.3)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.11/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.9.0)\n",
      "Collecting filelock (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.66.1)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.13.0->pyannote.audio)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.conda/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (23.2)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.10.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.1.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting sortedcontainers>=2.0.4 (from pyannote.core>=5.0.0->pyannote.audio)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting scipy>=1.1 (from pyannote.core>=5.0.0->pyannote.audio)\n",
      "  Downloading scipy-1.11.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas>=0.19 (from pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Downloading pandas-2.1.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Collecting typer>=0.2.1 (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting scikit-learn>=0.17.1 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tabulate>=0.7.7 in ./.conda/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Collecting matplotlib>=2.0.0 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting sympy>=1.1 (from pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading optuna-3.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote.audio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio) (2.17.2)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->pyannote.audio)\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio) (1.3.2)\n",
      "Collecting sentencepiece (from speechbrain>=0.5.14->pyannote.audio)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Collecting protobuf>=3.20 (from tensorboardX>=2.6->pyannote.audio)\n",
      "  Using cached protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting networkx (from torch>=2.0.0->pyannote.audio)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->pyannote.audio)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting librosa>=0.6.0 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.conda/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading numba-0.58.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pooch>=1.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading pooch-1.8.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading soxr-0.3.7-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting msgpack>=1.0 (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading msgpack-1.0.7-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.11/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning>=2.0.1->pyannote.audio) (69.0.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached contourpy-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Downloading fonttools-4.47.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading colorlog-6.8.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading SQLAlchemy-2.0.25-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.conda/lib/python3.11/site-packages (from typer>=0.2.1->typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio)\n",
      "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->pyannote.audio)\n",
      "  Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2023.11.17)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading Mako-1.3.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio)\n",
      "  Downloading llvmlite-0.41.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.conda/lib/python3.11/site-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio)\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp311-cp311-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.1.3-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading pytorch_metric_learning-2.4.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.6/630.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp311-none-macosx_10_9_x86_64.whl (146.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.1.2-cp311-cp311-macosx_10_13_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cffi-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl (182 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.1.4-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
      "Using cached scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "Downloading scipy-1.11.4-cp311-cp311-macosx_10_9_x86_64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Downloading pytorch_lightning-2.1.3-py3-none-any.whl (777 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp311-cp311-macosx_10_9_x86_64.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.6/397.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached contourpy-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl (258 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.47.0-cp311-cp311-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.5-cp311-cp311-macosx_10_9_x86_64.whl (68 kB)\n",
      "Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\n",
      "Downloading msgpack-1.0.7-cp311-cp311-macosx_10_9_x86_64.whl (235 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.2/235.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.58.1-cp311-cp311-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading soxr-0.3.7-cp311-cp311-macosx_10_9_x86_64.whl (414 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.4/414.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.25-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp311-cp311-macosx_10_9_x86_64.whl (31.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.8-cp311-cp311-macosx_10_9_universal2.whl (148 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.9/148.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: julius\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=668fc581cb5f7a219cf669cfe130983b03a903cd19d6eef1636c3dc5bb4fdc38\n",
      "  Stored in directory: /Users/darren.wallace/Library/Caches/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
      "Successfully built julius\n",
      "Installing collected packages: sortedcontainers, sentencepiece, pytz, primePy, mpmath, docopt, antlr4-python3-runtime, tzdata, typer, threadpoolctl, sympy, soxr, shellingham, semver, scipy, ruamel.yaml.clib, pyyaml, pyparsing, pycparser, protobuf, networkx, multidict, msgpack, mdurl, MarkupSafe, llvmlite, lightning-utilities, lazy-loader, kiwisolver, greenlet, fsspec, frozenlist, fonttools, filelock, einops, cycler, contourpy, colorlog, colorama, audioread, attrs, yarl, tensorboardX, sqlalchemy, scikit-learn, ruamel.yaml, pyannote.core, pooch, pandas, omegaconf, numba, matplotlib, markdown-it-py, Mako, jinja2, huggingface-hub, cffi, aiosignal, torch, soundfile, rich, hyperpyyaml, alembic, aiohttp, torchmetrics, torchaudio, pytorch-metric-learning, optuna, librosa, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.database, torch-audiomentations, pyannote.pipeline, pyannote.metrics, lightning, pyannote.audio\n",
      "Successfully installed Mako-1.3.0 MarkupSafe-2.1.3 aiohttp-3.9.1 aiosignal-1.3.1 alembic-1.13.1 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 attrs-23.2.0 audioread-3.0.1 cffi-1.16.0 colorama-0.4.6 colorlog-6.8.0 contourpy-1.2.0 cycler-0.12.1 docopt-0.6.2 einops-0.7.0 filelock-3.13.1 fonttools-4.47.0 frozenlist-1.4.1 fsspec-2023.12.2 greenlet-3.0.3 huggingface-hub-0.20.2 hyperpyyaml-1.2.2 jinja2-3.1.2 julius-0.2.7 kiwisolver-1.4.5 lazy-loader-0.3 librosa-0.10.1 lightning-2.1.3 lightning-utilities-0.10.0 llvmlite-0.41.1 markdown-it-py-3.0.0 matplotlib-3.8.2 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.7 multidict-6.0.4 networkx-3.2.1 numba-0.58.1 omegaconf-2.3.0 optuna-3.5.0 pandas-2.1.4 pooch-1.8.0 primePy-1.3 protobuf-4.25.1 pyannote.audio-3.1.1 pyannote.core-5.0.0 pyannote.database-5.0.1 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pycparser-2.21 pyparsing-3.1.1 pytorch-lightning-2.1.3 pytorch-metric-learning-2.4.1 pytz-2023.3.post1 pyyaml-6.0.1 rich-13.7.0 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 scikit-learn-1.3.2 scipy-1.11.4 semver-3.0.2 sentencepiece-0.1.99 shellingham-1.5.4 sortedcontainers-2.4.0 soundfile-0.12.1 soxr-0.3.7 speechbrain-0.5.16 sqlalchemy-2.0.25 sympy-1.12 tensorboardX-2.6.2.2 threadpoolctl-3.2.0 torch-2.1.2 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.4 torchaudio-2.1.2 torchmetrics-1.2.1 typer-0.9.0 tzdata-2023.4 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install   pyannote.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a 10 minute chunk of one of the Hwb videos to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio_path = \"audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3\"\n",
    "audio_chunk = AudioSegment.from_file(audio_path, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darren.wallace/wip/labs/Whisper-transcription_and_diarization-speaker-identification-/.conda/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/Users/darren.wallace/wip/labs/Whisper-transcription_and_diarization-speaker-identification-/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/darren.wallace/wip/labs/Whisper-transcription_and_diarization-speaker-identification-/.conda/lib/python3.11/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n",
      "speaker-embedding.onnx: 100%|██████████| 26.5M/26.5M [00:01<00:00, 17.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    'pyannote/speaker-diarization-3.0', use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization = pipeline(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Space-separated RTTM file format does not allow file URIs containing spaces (got: \"gareth gwyr_chunk0\").",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dump the diarization output to disk using RTTM format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3.rttm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rttm:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mdiarization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_rttm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrttm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/wip/labs/Whisper-transcription_and_diarization-speaker-identification-/.conda/lib/python3.11/site-packages/pyannote/core/annotation.py:413\u001b[0m, in \u001b[0;36mAnnotation.write_rttm\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_rttm\u001b[39m(\u001b[38;5;28mself\u001b[39m, file: TextIO):\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Dump annotation to file using RTTM format\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    ...     annotation.write_rttm(file)\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_rttm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/wip/labs/Whisper-transcription_and_diarization-speaker-identification-/.conda/lib/python3.11/site-packages/pyannote/core/annotation.py:378\u001b[0m, in \u001b[0;36mAnnotation._iter_rttm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, Text) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m uri:\n\u001b[1;32m    374\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpace-separated RTTM file format does not allow file URIs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontaining spaces (got: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment, _, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitertracks(yield_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(label, Text) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m label:\n",
      "\u001b[0;31mValueError\u001b[0m: Space-separated RTTM file format does not allow file URIs containing spaces (got: \"gareth gwyr_chunk0\")."
     ]
    }
   ],
   "source": [
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio/hwb_user_interviews/gareth gwyr/gareth gwyr_chunk0.mp3.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n",
    "    diarization.write"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
